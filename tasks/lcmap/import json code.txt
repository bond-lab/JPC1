import pandas as pd
import json
import os 
from difflib import get_close_matches

# --- 1. CONFIGURATION ---
# Path to the JSON file you want to process
FILE_TO_PROCESS = r"C:\Users\Mahdal\Desktop\Bond\chainnet_metonymy.json"
# MML_PATH should point to a non-existent file to force the use of the internal database
MML_PATH = r"C:\Users\Mahdal\Desktop\Bond\master_metaphor_list.txt"

# --- 2. DATA LOADING ---

def load_chainnet(filepath):
    chainnet_entries = []
    if not os.path.exists(filepath):
        print(f"‚ùå ERROR: File not found: {filepath}")
        return []

    # Determine type based on the filename
    file_name = os.path.basename(filepath).lower()
    default_type = "metonymy" if "metonymy" in file_name else "metaphor"

    print(f"   -> Reading file: {os.path.basename(filepath)} (Type: {default_type})")

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        # Data is either in 'content' key or the list itself
        items = data.get('content', []) if isinstance(data, dict) else data
        
        for item in items:
            # Extract word and ID from your specific keys
            lemma = item.get('wordform', 'unknown')
            sense_id = item.get('from_sense', 'N/A')

            chainnet_entries.append({
                'lemma': str(lemma).strip().lower(),
                'type': default_type,
                'sense_id': sense_id
            })
        
        print(f"   -> Loaded {len(chainnet_entries)} entries.")
                    
    except Exception as e:
        print(f"   ‚ùå Error reading JSON: {e}")

    return chainnet_entries

def load_mml(filepath):
    # Internal theory database (Master Metaphor List)
    backup_mml = {
        'ARGUMENT IS WAR': ['attack', 'defend', 'strategy', 'win', 'target', 'force', 'shot', 'twin', 'victory', 'fight'],
        'IDEAS ARE FOOD': ['digest', 'swallow', 'raw', 'bitter', 'cook', 'baked', 'spoon-feed'],
        'UNDERSTANDING IS SEEING': ['see', 'clear', 'focus', 'view', 'light', 'blight', 'vision', 'perspective'],
        'TIME IS MONEY': ['spend', 'waste', 'cost', 'invest', 'save', 'budget', 'borrow'],
        'LIFE IS A JOURNEY': ['path', 'road', 'step', 'way', 'arrival', 'crossroads', 'guide'],
        'CONTROL IS UP': ['rise', 'high', 'top', 'peak', 'superior', 'over', 'control'],
        'SOCIETY IS A BODY': ['head', 'heart', 'arm', 'member', 'organ', 'shoulder', 'brain']
    }
    return backup_mml

# --- 3. LINKING LOGIC ---

def link_metaphors(chainnet_data, mml_data):
    links = []
    print(f"   -> Searching for matches in MML theory...")

    # Flatten the MML word list for faster searching
    all_mml_words = {}
    for cm, words in mml_data.items():
        for w in words:
            all_mml_words[w] = cm

    for entry in chainnet_data:
        lemma = entry['lemma']
        best_match = None
        
        # Direct match
        if lemma in all_mml_words:
            best_match = all_mml_words[lemma]
        # Fuzzy match
        else:
            match = get_close_matches(lemma, list(all_mml_words.keys()), n=1, cutoff=0.8)
            if match:
                best_match = all_mml_words[match[0]]

        if best_match:
            links.append({
                'Word': lemma,
                'Type': entry['type'],
                'MML_Concept': best_match,
                'Sense_ID': entry['sense_id']
            })
            
    return links

# --- 4. EXECUTION ---

if __name__ == "__main__":
    print("\n--- STARTING MAPPER (v4) ---")
    
    chainnet = load_chainnet(FILE_TO_PROCESS)
    mml = load_mml(MML_PATH)
    
    if not chainnet:
        print("‚ùå No data to load.")
    else:
        results = link_metaphors(chainnet, mml)
        
        if results:
            df = pd.DataFrame(results)
            # Remove duplicates if the same word/ID maps to the same concept
            df = df.drop_duplicates()
            
            print(f"\n‚úÖ SUCCESS! Found {len(df)} unique links.")
            print("\n--- SAMPLE RESULTS ---")
            print(df.head(15).to_string(index=False))
            
            output_path = os.path.join(os.path.dirname(FILE_TO_PROCESS), "mapping_results_final.csv")
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"\nüíæ Saved to: {output_path}")
        else:
            print("\n‚ö†Ô∏è No matches found.")
